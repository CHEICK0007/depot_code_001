import queue
import json
import sounddevice as sd
from vosk import Model, KaldiRecognizer

from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms import Ollama
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 1Ô∏è‚É£ VOSK ‚Äî Reconnaissance vocale
vosk_model_path = r"C:\Users\PC\Documents\MES_CODES\python\projet_IA\vosk-model-small-fr-0.22\vosk-model-small-fr-0.22"
vosk_model = Model(vosk_model_path)
recognizer = KaldiRecognizer(vosk_model, 16000)
audio_queue = queue.Queue()

def audio_callback(indata, frames, time, status):
    if status:
        print("‚ö†Ô∏è", status)
    audio_queue.put(bytes(indata))

# 2Ô∏è‚É£ LangChain ‚Äî Chargement du RAG
loader = TextLoader("restaurant_info.json", encoding="utf-8")
documents = loader.load()

splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=50)
docs = splitter.split_documents(documents)

embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = Chroma.from_documents(docs, embedding)
retriever = vectorstore.as_retriever()
llm = Ollama(model="gemma3:1b")  # ou "gemma:1b-instruct"

# üîß Prompt contr√¥l√© (phrases simples, pas de redirection)
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
Tu es une secr√©taire. R√©ponds uniquement √† partir des informations suivantes, avec des phrases simples et pr√©cises.

 Ne redirige jamais vers un site web ou un num√©ro de t√©l√©phone.
 Si tu ne sais pas, dis : "Je n‚Äôai pas cette information."

Informations :
{context}

Question : {question}
R√©ponse :
"""
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt}
)

# 3Ô∏è‚É£ Boucle : √©coute ‚Üí texte ‚Üí r√©ponse
print("üéôÔ∏è Assistant en √©coute... (Ctrl+C pour arr√™ter)")
with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',
                       channels=1, callback=audio_callback):
    try:
        while True:
            data = audio_queue.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                phrase = result.get("text", "").strip()
                if phrase:
                    print("üó£Ô∏è Question :", phrase)
                    response = qa_chain.run(phrase)
                    print("ü§ñ R√©ponse :", response)
    except KeyboardInterrupt:
        print("\n Assistant arr√™t√©.")
