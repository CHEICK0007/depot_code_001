import queue
import json
import sounddevice as sd
from vosk import Model, KaldiRecognizer

from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms import Ollama
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter


# comfigurattion

# ğŸ“„ Charge un document (ex: fichier JSON ou texte)
loader = TextLoader("restaurant_info.json", encoding="utf-8")
documents = loader.load()

# âœ‚ï¸ DÃ©coupe le texte en morceaux plus courts
text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

# ğŸ§  Embeddings + indexation
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = Chroma.from_documents(docs, embedding)

# ğŸ” Construction de la chaÃ®ne RAG
retriever = vectorstore.as_retriever()
llm = Ollama(model="gemma3:1b")



# Template & RAG

prompt_template1 = PromptTemplate(
    input_variables=["context", "question"],
    template="""
Tu es un assistant de restaurant qui ne salue JAMAIS. RÃ©ponds strictement selon ces rÃ¨gles :

1. **Sources** : Utilise uniquement ces donnÃ©es :
{context}

2. **Format** : 
- Pas de demande d'informations personnelles

3. **Restrictions** :

- Jamais de sites web/numÃ©ros de tÃ©lÃ©phone
- Jamais de "veuillez contacter..." ou "vous pouvez trouver..."
- ne donne pas de rÃ©ponses si tu n'en n'as pas 
Question : {question}
RÃ©ponse :
"""
)

qa_chain1 = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt_template1}
)


# discussion Vocal

# ğŸ’¾ Initialise un historique de conversation
conversation_history = ""
q = queue.Queue()
def callback(indata, frames, time, status):
    if status:
        print("âš ï¸", status)
    q.put(bytes(indata))

model = Model(r"C:\Users\PC\Documents\MES_CODES\python\projet_IA\vosk-model-small-fr-0.22\vosk-model-small-fr-0.22")
recognizer = KaldiRecognizer(model, 16000)

print("ğŸ™ï¸ Assistant en Ã©coute... (Ctrl+C pour arrÃªter)")
print("ğŸ™ï¸ Assistant en Ã©coute... (Ctrl+C pour arrÃªter)")

with sd.RawInputStream(samplerate=16000, blocksize=8000, dtype='int16',
                       channels=1, callback=callback):
    try:
        info_dis = []
        while True:
            data = q.get()
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                phrase = result.get("text", "").strip()
                if phrase:
                    print("ğŸ—£ï¸ Question :", phrase)
                    info_dis.append(phrase)

                    # ğŸ” On construit le prompt avec l'historique
                    full_prompt = f"""
                    [Historique de la conversation jusqu'Ã  prÃ©sent]
                    {conversation_history}

                    Maintenant, rÃ©ponds Ã  SEULEMENT et cette nouvelle question de l'utilisateur :

                    [Nouvelle question]
                    {phrase}
                    """
                    # ğŸ§  RequÃªte au modÃ¨le
                    response = qa_chain1.run(full_prompt)

                    # ğŸ”‚ Ajoute l'Ã©change Ã  l'historique pour crÃ©er une chaÃ®ne de questions-rÃ©ponses (conversation)
                    conversation_history += f"\nUtilisateur : {phrase}\nAssistant : {response}"

                    print("ğŸ¤– RÃ©ponse :", response)
                    lire_texte(response)

    except KeyboardInterrupt:
     print("\nğŸ›‘ Assistant arrÃªtÃ©.")
